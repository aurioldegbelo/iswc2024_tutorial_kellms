{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kellm-fit/ISWC_tutorial/blob/main/session-3/hands-on/graphrag_rdf_kg_construction.ipynb)\n",
    "\n",
    "## Prepare Notebook for Colab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/kellm-fit/ISWC_tutorial.git"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_path = \"/content/ISWC_tutorial/session-3/hands-on/\"\n",
    "# For local\n",
    "# base_path = \"./\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Knowledge Graph Construction Overview\n",
    "1. Environment Setup: Install necessary Python libraries.\n",
    "2. Data Ingestion: Read Parquet files into Pandas DataFrames.\n",
    "3. RDF Graph Initialization: Set up the RDF graph using rdflib.\n",
    "4. Ontology Definition: Define classes and properties in RDF.\n",
    "5. Mapping Nodes and Relationships to RDF: Convert each node and its relationships into RDF triples.\n",
    "6. Serializing the RDF Graph: Export the RDF graph in your preferred format.\n",
    "7. Example Queries (Optional): Execute SPARQL queries on the RDF graph.\n",
    "8. Ontology Visualization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "Ensure you have the required Python libraries installed. We'll use pandas and pyarrow for handling Parquet files, and rdflib for creating and managing RDF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow==17.0.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: rdflib==7.0.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: pyvis==0.3.2 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: networkx==3.3 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (3.3)\n",
      "Requirement already satisfied: ipysigma==0.24.2 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pandas==2.2.3) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pandas==2.2.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pandas==2.2.3) (2024.1)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from rdflib==7.0.0) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from rdflib==7.0.0) (3.1.4)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pyvis==0.3.2) (8.27.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pyvis==0.3.2) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from pyvis==0.3.2) (3.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipysigma==0.24.2) (8.1.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->ipysigma==0.24.2) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->ipysigma==0.24.2) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->ipysigma==0.24.2) (3.0.13)\n",
      "Requirement already satisfied: six in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib==7.0.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from jinja2>=2.9.6->pyvis==0.3.2) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis==0.3.2) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis==0.3.2) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\liao\\desktop\\workspace\\project\\iswc tutorial\\venv\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas==2.2.2 pyarrow==17.0.0 rdflib==7.0.0 pyvis==0.3.2 networkx==3.3 ipysigma==0.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "kg_path = os.path.join(os.getcwd(), 'kg')\n",
    "\n",
    "# Read Parquet files\n",
    "documents_df = pd.read_parquet(os.path.join(kg_path, 'create_final_documents.parquet'))\n",
    "entities_df = pd.read_parquet(os.path.join(kg_path, 'create_final_entities.parquet'))\n",
    "relationships_df = pd.read_parquet(os.path.join(kg_path, 'create_final_relationships.parquet'))\n",
    "text_units_df = pd.read_parquet(os.path.join(kg_path, 'create_final_text_units.parquet'))\n",
    "community_reports_df = pd.read_parquet(os.path.join(kg_path, 'create_final_community_reports.parquet'))\n",
    "communities_df = pd.read_parquet(os.path.join(kg_path, 'create_final_communities.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>graph_embedding</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>description_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23e483d08c6f4f3297707b38926ba21d</td>\n",
       "      <td>CAUSAL DISCOVERY</td>\n",
       "      <td>SCIENTIFIC DISCIPLINE, METHOD</td>\n",
       "      <td>Causal discovery is a process in scientific re...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[5102919b3ad27254673948bab8a72ed8, 6b1091d4897...</td>\n",
       "      <td>[-0.004210005979984999, 0.006614891812205315, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id              name  \\\n",
       "0  23e483d08c6f4f3297707b38926ba21d  CAUSAL DISCOVERY   \n",
       "\n",
       "                            type  \\\n",
       "0  SCIENTIFIC DISCIPLINE, METHOD   \n",
       "\n",
       "                                         description  human_readable_id  \\\n",
       "0  Causal discovery is a process in scientific re...                  0   \n",
       "\n",
       "  graph_embedding                                      text_unit_ids  \\\n",
       "0            None  [5102919b3ad27254673948bab8a72ed8, 6b1091d4897...   \n",
       "\n",
       "                               description_embedding  \n",
       "0  [-0.004210005979984999, 0.006614891812205315, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: RDF Graph Initialization\n",
    "Initialize the RDF graph and define the necessary namespaces. We'll use a base namespace (`EX`) for your data and an ontology namespace (`ONTO`) for defining classes and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Namespace, URIRef, BNode, Literal, Graph\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD, FOAF\n",
    "\n",
    "# Initialize RDF Graph\n",
    "rdf_graph = Graph()\n",
    "\n",
    "# Define Namespaces\n",
    "EX = Namespace(\"http://example.org/data#\")\n",
    "ONTO = Namespace(\"http://example.org/ontology#\")\n",
    "\n",
    "# Bind namespaces to prefixes for readability\n",
    "rdf_graph.bind(\"ex\", EX)\n",
    "rdf_graph.bind(\"onto\", ONTO)\n",
    "rdf_graph.bind(\"rdf\", RDF)\n",
    "rdf_graph.bind(\"rdfs\", RDFS)\n",
    "rdf_graph.bind(\"owl\", OWL)\n",
    "rdf_graph.bind(\"foaf\", FOAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Ontology Definition\n",
    "Define RDF classes and properties based on the structure of generated Parquet files. This step establishes the semantic structure of the RDF graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Namespace, RDF, RDFS, OWL, XSD\n",
    "\n",
    "# --- Define Classes ---\n",
    "classes = [\n",
    "    \"Document\",\n",
    "    \"Entity\",\n",
    "    \"Relationship\",\n",
    "    \"TextUnit\",\n",
    "    \"CommunityReport\",\n",
    "    \"Community\",    \n",
    "    \"Finding\"\n",
    "]\n",
    "\n",
    "for cls in classes:\n",
    "    rdf_graph.add((ONTO[cls], RDF.type, OWL.Class))\n",
    "\n",
    "# --- Define Properties ---\n",
    "\n",
    "# Object Properties\n",
    "object_properties = {\n",
    "    \"hasTextUnit\": {\n",
    "        \"domain\": \"Document\",\n",
    "        \"range\": \"TextUnit\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"referencesEntity\": {\n",
    "        \"domain\": \"TextUnit\",\n",
    "        \"range\": \"Entity\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"hasFinding\": {\n",
    "        \"domain\": \"CommunityReport\",\n",
    "        \"range\": \"Finding\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"isInCommunity\": {\n",
    "        \"domain\": \"Entity\",\n",
    "        \"range\": \"Community\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"relates\": {\n",
    "        \"domain\": \"Entity\",\n",
    "        \"range\": \"Entity\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"source\": {\n",
    "        \"domain\": \"Relationship\",\n",
    "        \"range\": \"Entity\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"domain\": \"Relationship\",\n",
    "        \"range\": \"Entity\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"referencesRelationship\": {\n",
    "        \"domain\": \"TextUnit\",\n",
    "        \"range\": \"Relationship\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "    \"hasCommunityReport\": {\n",
    "        \"domain\": \"Community\",\n",
    "        \"range\": \"CommunityReport\",\n",
    "        \"type\": OWL.ObjectProperty\n",
    "    },\n",
    "}\n",
    "\n",
    "# Datatype Properties\n",
    "datatype_properties = {\n",
    "    \"hasTitle\": {\n",
    "        \"domain\": [\"Document\", \"Community\", \"CommunityReport\"],\n",
    "        \"range\": XSD.string,        \n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasRawContent\": {\n",
    "        \"domain\": \"Document\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasName\": {\n",
    "        \"domain\": \"Entity\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasType\": {\n",
    "        \"domain\": [\"Entity\"],\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasDescription\": {\n",
    "        \"domain\": [\"Entity\", \"Relationship\"],\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasDescriptionEmbedding\": {\n",
    "        \"domain\": \"Entity\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasHumanReadableId\": {\n",
    "        \"domain\": [\"Entity\", \"Relationship\"],\n",
    "        \"range\": XSD.integer,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasWeight\": {\n",
    "        \"domain\": \"Relationship\",\n",
    "        \"range\": XSD.integer,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasSourceName\": {\n",
    "        \"domain\": \"Relationship\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasTargetName\": {\n",
    "        \"domain\": \"Relationship\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasText\": {\n",
    "        \"domain\": \"TextUnit\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasNToken\": {\n",
    "        \"domain\": [\"TextUnit\"],\n",
    "        \"range\": XSD.integer,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasLevel\": {\n",
    "        \"domain\": [\"Community\", \"CommunityReport\"],\n",
    "        \"range\": XSD.integer,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasRank\": {\n",
    "        \"domain\": [\"Community\", \"CommunityReport\", \"Relationship\"],\n",
    "        \"range\": XSD.integer,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasSummary\": {\n",
    "        \"domain\": [\"CommunityReport\", \"Finding\"],\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    }, \n",
    "    \"hasExplanation\": {\n",
    "        \"domain\": \"Finding\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasFullContent\": {\n",
    "        \"domain\": \"CommunityReport\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },\n",
    "    \"hasFullContentJSON\": {\n",
    "        \"domain\": \"CommunityReport\",\n",
    "        \"range\": XSD.string,\n",
    "        \"type\": OWL.DatatypeProperty\n",
    "    },    \n",
    "}\n",
    "\n",
    "# Add Object Properties to the Graph\n",
    "for prop, details in object_properties.items():\n",
    "    rdf_graph.add((ONTO[prop], RDF.type, details[\"type\"]))\n",
    "    rdf_graph.add((ONTO[prop], RDFS.domain, ONTO[details[\"domain\"]]))\n",
    "    rdf_graph.add((ONTO[prop], RDFS.range, ONTO[details[\"range\"]]))\n",
    "\n",
    "# Add Datatype Properties to the Graph\n",
    "for prop, details in datatype_properties.items():\n",
    "    rdf_graph.add((ONTO[prop], RDF.type, details[\"type\"]))\n",
    "    # Handle multiple domains\n",
    "    domains = details[\"domain\"] if isinstance(details[\"domain\"], list) else [details[\"domain\"]]\n",
    "    for domain in domains:\n",
    "        rdf_graph.add((ONTO[prop], RDFS.domain, ONTO[domain]))\n",
    "    rdf_graph.add((ONTO[prop], RDFS.range, details[\"range\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Mapping Nodes to RDF\n",
    "Convert each node type from the Parquet files into RDF triples. This involves iterating through each DataFrame and creating corresponding RDF resources with their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Helper Function\n",
    "`remove_quotes` removes leading/trailing quotes from strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotes(string):\n",
    "    return string.strip('\"').strip(\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Documents\n",
    "Each `Document` is mapped to an RDF node with its properties (title, raw content) and linked to its `TextUnits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in documents_df.iterrows():\n",
    "    doc_uri = EX[f\"Document_{row['id']}\"]    \n",
    "    rdf_graph.add((doc_uri, RDF.type, ONTO.Document))\n",
    "    rdf_graph.add((doc_uri, ONTO.hasTitle, Literal(row['title'], datatype=XSD.string)))\n",
    "    rdf_graph.add((doc_uri, ONTO.hasRawContent, Literal(row['raw_content'], datatype=XSD.string)))\n",
    "    \n",
    "    # Link to TextUnits\n",
    "    for tu_id in row['text_unit_ids']:\n",
    "        tu_uri = EX[f\"TextUnit_{tu_id}\"]        \n",
    "        rdf_graph.add((doc_uri, ONTO.hasTextUnit, tu_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Entities\n",
    "`Entity` nodes are created with properties (name, type, description, etc.) and linked to relevant `TextUnits` and `Communities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_name_to_id = dict(zip(entities_df['name'], entities_df['id']))\n",
    "for _, row in entities_df.iterrows():\n",
    "    entity_uri = EX[f\"Entity_{row['id']}\"]    \n",
    "    rdf_graph.add((entity_uri, RDF.type, ONTO.Entity))    \n",
    "    rdf_graph.add((entity_uri, ONTO.hasName, Literal(remove_quotes(row['name']), datatype=XSD.string)))\n",
    "    rdf_graph.add((entity_uri, ONTO.hasType, Literal(remove_quotes(row['type']), datatype=XSD.string)))\n",
    "    rdf_graph.add((entity_uri, ONTO.hasDescription, Literal(remove_quotes(row['description']), datatype=XSD.string)))\n",
    "    rdf_graph.add((entity_uri, ONTO.hasHumanReadableId, Literal(int(row['human_readable_id']), datatype=XSD.integer)))\n",
    "    embedding_str = \" \".join(map(str, row['description_embedding']))    \n",
    "    rdf_graph.add((entity_uri, ONTO.hasDescriptionEmbedding, Literal(embedding_str, datatype=XSD.string)))\n",
    "                \n",
    "    # Link to TextUnits\n",
    "    for tu_id in row['text_unit_ids']:\n",
    "        tu_uri = EX[f\"TextUnit_{tu_id}\"]\n",
    "        rdf_graph.add((entity_uri, ONTO.referencesEntity, tu_uri))\n",
    "\n",
    "for _, row in communities_df.iterrows():\n",
    "    community_uri = EX[f\"Community_{row['id']}\"]\n",
    "    \n",
    "    # Get the list of relationship IDs associated with the community\n",
    "    relationship_ids = row['relationship_ids']\n",
    "    \n",
    "    for rel_id in relationship_ids:\n",
    "        # Find the corresponding relationship row in relationships_df\n",
    "        relationship_row = relationships_df[relationships_df['id'] == rel_id].iloc[0]\n",
    "        source_entity_id = entity_name_to_id[relationship_row['source']]\n",
    "        target_entity_id = entity_name_to_id[relationship_row['target']]\n",
    "        \n",
    "        # Create URIs for source and target entities\n",
    "        source_entity_uri = EX[f\"Entity_{source_entity_id}\"]\n",
    "        target_entity_uri = EX[f\"Entity_{target_entity_id}\"]\n",
    "        \n",
    "        # Link source and target entities to the community using IN_COMMUNITY\n",
    "        rdf_graph.add((source_entity_uri, ONTO.isInCommunity, community_uri))\n",
    "        rdf_graph.add((target_entity_uri, ONTO.isInCommunity, community_uri))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Relationships\n",
    "`Relationship` nodes connect source and target `Entities`, containing properties (description, rank, weight, etc.) and linked to `TextUnits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in relationships_df.iterrows():\n",
    "    rel_uri = EX[f\"Relationship_{row['id']}\"]\n",
    "    \n",
    "    rdf_graph.add((rel_uri, RDF.type, ONTO.Relationship))\n",
    "    rdf_graph.add((rel_uri, ONTO.hasWeight, Literal(row['weight'], datatype=XSD.integer)))        \n",
    "    rdf_graph.add((rel_uri, ONTO.hasRank, Literal(row['rank'], datatype=XSD.integer))) \n",
    "    rdf_graph.add((rel_uri, ONTO.hasDescription, Literal(remove_quotes(row['description']), datatype=XSD.string)))    \n",
    "    rdf_graph.add((rel_uri, ONTO.hasHumanReadableId, Literal(int(row['human_readable_id']), datatype=XSD.integer)))\n",
    "    rdf_graph.add((rel_uri, ONTO.hasSourceName, Literal(remove_quotes(row['source']), datatype=XSD.string)))\n",
    "    rdf_graph.add((rel_uri, ONTO.hasTargetName, Literal(remove_quotes(row['target']), datatype=XSD.string)))\n",
    "    # Link to Source and Target Entities    \n",
    "    source_uri = EX[f\"Entity_{entity_name_to_id[row['source']]}\"]\n",
    "    target_uri = EX[f\"Entity_{entity_name_to_id[row['target']]}\"]\n",
    "    rdf_graph.add((rel_uri, ONTO.source, source_uri))\n",
    "    rdf_graph.add((rel_uri, ONTO.target, target_uri))\n",
    "    \n",
    "    rdf_graph.add((source_uri, ONTO.relates, target_uri))\n",
    "    \n",
    "    # Link to TextUnits\n",
    "    for tu_id in row['text_unit_ids']:\n",
    "        tu_uri = EX[f\"TextUnit_{tu_id}\"]\n",
    "        rdf_graph.add((rel_uri, ONTO.referencesRelationship, tu_uri))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 TextUnits\n",
    "`TextUnit` nodes represent document chunks, linked back to `Documents`, `Entities`, and `Relationships`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in text_units_df.iterrows():\n",
    "    tu_uri = EX[f\"TextUnit_{row['id']}\"]\n",
    "    rdf_graph.add((tu_uri, RDF.type, ONTO.TextUnit))\n",
    "    rdf_graph.add((tu_uri, ONTO.hasText, Literal(row['text'], datatype=XSD.string)))\n",
    "    rdf_graph.add((tu_uri, ONTO.hasNToken, Literal(row['n_tokens'], datatype=XSD.integer)))\n",
    "    \n",
    "    # Link to Documents\n",
    "    if row['document_ids'] is not None:\n",
    "        for doc_id in row['document_ids']:\n",
    "            doc_uri = EX[f\"Document_{doc_id}\"]\n",
    "            rdf_graph.add((tu_uri, ONTO.belongsToDocument, doc_uri))\n",
    "    \n",
    "    # Link to Entities\n",
    "    if row['entity_ids'] is not None:\n",
    "        for entity_id in row['entity_ids']:\n",
    "            entity_uri = EX[f\"Entity_{entity_id}\"]\n",
    "            rdf_graph.add((tu_uri, ONTO.referencesEntity, entity_uri))\n",
    "    \n",
    "    # Link to Relationships    \n",
    "    if row['relationship_ids'] is not None:\n",
    "        for rel_id in row['relationship_ids']:\n",
    "            rel_uri = EX[f\"Relationship_{rel_id}\"]\n",
    "            rdf_graph.add((tu_uri, ONTO.referencesRelationship, rel_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Community Reports\n",
    "`CommunityReport` nodes store report details (content, title, findings, etc.) and link to their respective `Communities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from Community ID to Community URI\n",
    "community_id_to_uri = {}\n",
    "\n",
    "for _, row in communities_df.iterrows():\n",
    "    community_id = row['id']  # Assuming 'id' is the numeric human-readable ID\n",
    "    community_uri = EX[f\"Community_{community_id}\"]    \n",
    "    community_id_to_uri[community_id] = community_uri\n",
    "\n",
    "for _, row in community_reports_df.iterrows():\n",
    "    cr_id = row['id']\n",
    "    cr_uri = EX[f\"CommunityReport_{cr_id}\"]\n",
    "    \n",
    "    # Add CommunityReport as an instance of ONTO.CommunityReport\n",
    "    rdf_graph.add((cr_uri, RDF.type, ONTO.CommunityReport))\n",
    "    \n",
    "    # Link to Community using the human-readable community ID\n",
    "    community_hr_id = row['community']  # e.g., 1, 2, 3, 4\n",
    "    community_uri = community_id_to_uri.get(community_hr_id)\n",
    "    if community_uri:\n",
    "        rdf_graph.add((cr_uri, ONTO.hasCommunity, community_uri))\n",
    "    else:\n",
    "        print(f\"Warning: Community ID {community_hr_id} not found for CommunityReport ID {cr_id}\")\n",
    "    \n",
    "    # Add other properties\n",
    "    rdf_graph.add((cr_uri, ONTO.hasFullContent, Literal(row['full_content'], datatype=XSD.string)))\n",
    "    rdf_graph.add((cr_uri, ONTO.hasLevel, Literal(row['level'], datatype=XSD.integer)))\n",
    "    rdf_graph.add((cr_uri, ONTO.hasRank, Literal(row['rank'], datatype=XSD.integer)))\n",
    "    rdf_graph.add((cr_uri, ONTO.hasTitle, Literal(row['title'], datatype=XSD.string)))\n",
    "    rdf_graph.add((cr_uri, ONTO.hasSummary, Literal(row['summary'], datatype=XSD.string)))\n",
    "    rdf_graph.add((cr_uri, ONTO.hasFullContentJSON, Literal(row['full_content_json'], datatype=XSD.string)))\n",
    "    \n",
    "    # Handle Findings    \n",
    "    for finding in row['findings']:        \n",
    "        finding_explanation = finding.get('explanation', '')\n",
    "        finding_summary = finding.get('summary', '')\n",
    "        \n",
    "        # Create a Finding URI or use a blank node\n",
    "        finding_bnode = BNode()\n",
    "        rdf_graph.add((finding_bnode, RDF.type, ONTO.Finding))\n",
    "        \n",
    "        # Add explanation and summary\n",
    "        rdf_graph.add((finding_bnode, ONTO.hasExplanation, Literal(finding_explanation, datatype=XSD.string)))\n",
    "        rdf_graph.add((finding_bnode, ONTO.hasSummary, Literal(finding_summary, datatype=XSD.string)))\n",
    "        \n",
    "        # Link Finding to CommunityReport\n",
    "        rdf_graph.add((cr_uri, ONTO.hasFinding, finding_bnode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Communities\n",
    "`Community` nodes group related entities and relationships, linking to `TextUnits`, `Relationships`, and `CommunityReports`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in communities_df.iterrows():\n",
    "    community_uri = EX[f\"Community_{row['id']}\"]\n",
    "    rdf_graph.add((community_uri, RDF.type, ONTO.Community))\n",
    "    rdf_graph.add((community_uri, ONTO.hasTitle, Literal(row['title'], datatype=XSD.string)))\n",
    "    rdf_graph.add((community_uri, ONTO.hasLevel, Literal(row['level'], datatype=XSD.integer)))    \n",
    "    \n",
    "    # Link to Relationships\n",
    "    for rel_id in row['relationship_ids']:\n",
    "        rel_uri = EX[f\"Relationship_{rel_id}\"]\n",
    "        rdf_graph.add((community_uri, ONTO.referencesRelationship, rel_uri))\n",
    "        \n",
    "    # Link to TextUnits\n",
    "    for tu_id in row['text_unit_ids']:        \n",
    "        tu_uri = EX[f\"TextUnit_{tu_id}\"]\n",
    "        rdf_graph.add((community_uri, ONTO.referencesTextUnit, tu_uri))\n",
    "\n",
    "# Link to CommunityReports\n",
    "for _, row in community_reports_df.iterrows():\n",
    "    cr_uri = EX[f\"CommunityReport_{row['id']}\"]\n",
    "    community_number = row['community']\n",
    "    community_uri = EX[f\"Community_{community_number}\"]\n",
    "    rdf_graph.add((community_uri, ONTO.hasCommunityReport, cr_uri))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Serializing the RDF Graph\n",
    "Once all nodes and relationships have been mapped, serialize the RDF graph into a desired format such as Turtle (.ttl), RDF/XML, or JSON-LD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF graph has been serialized to 'global_graph.ttl'\n"
     ]
    }
   ],
   "source": [
    "# Serialize as Turtle\n",
    "turtle_data = rdf_graph.serialize(format='turtle')\n",
    "\n",
    "# Save to a file\n",
    "with open('global_graph.ttl', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(turtle_data)\n",
    "\n",
    "print(\"RDF graph has been serialized to 'global_graph.ttl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Example Queries (Optional)\n",
    "This code demonstrates querying an RDF graph with `rdflib` to retrieve names and descriptions of up to three entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: http://example.org/data#Entity_01b840a5b1f44c42a27207c492c915f1, Name: WANG, Y., Description: Wang, Y. is an author and researcher involved in structure-augmented text representation learning for efficient knowledge graph completion\n",
      "Entity: http://example.org/data#Entity_01eefacdb0694a15b39358fdbab3e40a, Name: CHEN, W., Description: W. Chen is an author and researcher known for work on relational rules for knowledge graph link prediction\n",
      "Entity: http://example.org/data#Entity_06a23c47a64f4a95b6b0951c9211233b, Name: KWOK, J.T., Description: Kwok, J.T. is an author and researcher involved in the development of KICGPT, a large language model for knowledge graph completion\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, RDF, OWL\n",
    "\n",
    "# Initialize RDF Graph and define namespaces\n",
    "rdf_graph = Graph()\n",
    "\n",
    "# Load the TTL file\n",
    "rdf_graph.parse(\"global_graph.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define and execute the SPARQL query to extract all instances of 'Entity'\n",
    "query = \"\"\"\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>    \n",
    "    PREFIX onto: <http://example.org/ontology#>\n",
    "    \n",
    "    SELECT ?entity ?name ?description\n",
    "    WHERE {\n",
    "        ?entity rdf:type onto:Entity .\n",
    "        ?entity onto:hasName ?name .\n",
    "        ?entity onto:hasDescription ?description .\n",
    "    }\n",
    "    limit 3\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "results = rdf_graph.query(query)\n",
    "\n",
    "# Print the results\n",
    "for entity, name, desc in results:\n",
    "    print(f\"Entity: {entity}, Name: {name}, Description: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Ontology Visualization\n",
    "This section visualizes the ontology using NetworkX, PyVis, and Sigma to represent the structure of the RDF graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 36824 triples.\n",
      "Classes: 7\n",
      "Object Properties: 9\n",
      "Datatype Properties: 18\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, OWL\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "g = Graph()\n",
    "\n",
    "g.parse(\"global_graph.ttl\", format=\"turtle\")\n",
    "\n",
    "print(f\"Graph has {len(g)} triples.\")\n",
    "\n",
    "classes = set(g.subjects(RDF.type, OWL.Class))\n",
    "\n",
    "# Extract Object and Datatype Properties\n",
    "object_properties = set(g.subjects(RDF.type, OWL.ObjectProperty))\n",
    "datatype_properties = set(g.subjects(RDF.type, OWL.DatatypeProperty))\n",
    "\n",
    "# Display the results\n",
    "print(f\"Classes: {len(classes)}\")\n",
    "print(f\"Object Properties: {len(object_properties)}\")\n",
    "print(f\"Datatype Properties: {len(datatype_properties)}\")\n",
    "\n",
    "nx_graph = nx.MultiDiGraph()\n",
    "\n",
    "# Helper function to get short names (remove prefixes)\n",
    "def get_short_name(uri):\n",
    "    return uri.split('#')[-1] if '#' in uri else uri.split('/')[-1]\n",
    "\n",
    "# Add classes as nodes with short labels and color\n",
    "for cls in classes:\n",
    "    nx_graph.add_node(str(cls), label=get_short_name(str(cls)), color=\"lightblue\")  # Use class short name and set color\n",
    "\n",
    "# Add object properties as edges between their domain and range, label with property name\n",
    "for prop in object_properties:\n",
    "    domain = g.value(prop, RDFS.domain)\n",
    "    range_ = g.value(prop, RDFS.range)\n",
    "    if domain and range_:\n",
    "        nx_graph.add_node(str(domain), label=get_short_name(str(domain)), color=\"lightgreen\")  # Use short name\n",
    "        nx_graph.add_node(str(range_), label=get_short_name(str(range_)), color=\"lightgreen\")  # Use short name\n",
    "        nx_graph.add_edge(str(domain), str(range_), label=get_short_name(str(prop)), color=\"blue\")  # Short name for edge label\n",
    "\n",
    "# Add datatype properties as edges between classes and literals, label with property name\n",
    "for prop in datatype_properties:\n",
    "    # Find domains and ranges for each datatype property\n",
    "    domains = list(g.objects(prop, RDFS.domain))\n",
    "    range_ = g.value(prop, RDFS.range)\n",
    "    \n",
    "    if domains and range_:\n",
    "        for domain in domains:\n",
    "            nx_graph.add_node(str(domain), label=get_short_name(str(domain)), color=\"lightgreen\")  # Use short name\n",
    "            nx_graph.add_node(str(range_), label=get_short_name(str(range_)), color=\"orange\")  # Datatypes in orange\n",
    "            nx_graph.add_edge(str(domain), str(range_), label=get_short_name(str(prop)), color=\"green\")  # Short name for edge label\n",
    "\n",
    "# Create a PyVis network for visualization\n",
    "nt = Network(notebook=True, height=\"1000px\", width=\"100%\", directed=True)\n",
    "nt.from_nx(nx_graph)\n",
    "\n",
    "# Generate the interactive HTML file\n",
    "nt.write_html(\"ontology_visualization.html\", open_browser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68265c057b424317920777818fc83f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sigma(nx.MultiDiGraph with 9 nodes and 35 edges)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipysigma import Sigma\n",
    "\n",
    "sigma = Sigma(\n",
    "    nx_graph,\n",
    "    default_edge_type=\"curve\",    \n",
    "    clickable_edges =True,\n",
    "    node_border_color_from=\"node\",    \n",
    "    label_font=\"cursive\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
